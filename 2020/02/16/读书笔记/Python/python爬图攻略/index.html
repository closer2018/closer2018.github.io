<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png"><link rel="icon" type="image/png" href="/img/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content="沧海横流，尽显英雄本色；激浊扬清，正是猛士当时"><meta name="author" content="closer"><meta name="keywords" content=""><title>python爬图攻略 - closer的自留地</title><link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/androidstudio.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_fmb4a04yx8h.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css"><link rel="stylesheet" href="/css/main.css"><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="closer的自留地" type="application/atom+xml"></head><body><header style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/">&nbsp;<strong>Welcome!</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item"><a class="nav-link" href="/links/"><i class="iconfont icon-link-fill"></i> 友链</a></li><li class="nav-item" id="search-btn"><a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i class="iconfont icon-search"></i>&nbsp;&nbsp;</a></li></ul></div></div></nav><div class="view intro-2" id="background" parallax="true" style="background:url(/img/default.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="container text-center white-text fadeInUp"><span class="h2" id="subtitle"></span><div class="mt-3 post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2020-02-16 10:54">2020年2月16日 上午</time></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 2k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 32 分钟 </span><span id="busuanzi_container_page_pv" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid"><div class="row"><div class="d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-md"><div class="container nopadding-md" id="board-ctn"><div class="py-5" id="board"><div class="post-content mx-auto" id="post"><p class="note note-info">本文最后更新于：2020年2月23日 下午</p><article class="markdown-body"><h2 id="一：-软件工具">一： 软件工具</h2><h3 id="1-1-Python3">1.1 Python3</h3><p>这里选择的是最新版 Python3<br>安装教程这里推荐：<a href="http://www.runoob.com/python3/python3-install.html" target="_blank" rel="noopener">http://www.runoob.com/python3/python3-install.html</a><br>win下载地址：<a href="https://www.python.org/downloads/windows" target="_blank" rel="noopener">https://www.python.org/downloads/windows</a><br>Linux下载地址：<a href="https://www.python.org/downloads/source" target="_blank" rel="noopener">https://www.python.org/downloads/source</a><a id="more"></a></p><h3 id="1-2-PyCharm">1.2 PyCharm</h3><p>可视化开发工具IDE：<a href="https://www.jetbrains.com/pycharm/download/" target="_blank" rel="noopener">https://www.jetbrains.com/pycharm/download/</a></p><h2 id="二：原理">二：原理</h2><h3 id="2-1-实现步骤">2.1 实现步骤</h3><p>以图片为例，其实很简单，分以下四步：</p><ul><li>获取首页的页码数，并创建与页码对应的文件夹</li><li>获取页面的栏目地址</li><li>进入栏目，获取栏目页码数(每个栏目下有多张图片，分页显示)</li><li>获取到栏目下对用标签容器中的图片并下载</li></ul><h3 id="2-2-注意事项">2.2 注意事项</h3><p>这里以爬取某个网站的套路为例，详细见代码，这里主要说以下几点注意事项：</p><p>1）导库，其实就类似于Java中框架或者是工具类，底层都被封装好了</p><p>安装第三方库：</p><div class="hljs"><pre><code class="hljs py"><span class="hljs-comment"># Win下直接装的 python3</span>
pip install BeautifulSoup4 -i https://pypi.tuna.tsinghua.edu.cn/simple
pip install requests -i https://pypi.tuna.tsinghua.edu.cn/simple
<span class="hljs-comment"># Linux python2 python3 共存</span>
pip3 install BeautifulSoup4 -i https://pypi.tuna.tsinghua.edu.cn/simple
pip3 install requests -i https://pypi.tuna.tsinghua.edu.cn/simple</code></pre></div><p>导入第三方库：</p><div class="hljs"><pre><code class="hljs py"><span class="hljs-comment"># 导入requests库</span>
<span class="hljs-keyword">import</span> requests
<span class="hljs-comment"># 导入文件操作库</span>
<span class="hljs-keyword">import</span> os
<span class="hljs-comment"># bs4全名BeautifulSoup4，是编写python爬虫常用库之一，主要用来解析html标签。</span>
<span class="hljs-keyword">import</span> bs4
<span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup
<span class="hljs-comment"># 基础类库</span>
<span class="hljs-keyword">import</span> sys
<span class="hljs-comment"># Python 3.x 解决中文编码问题</span>
<span class="hljs-keyword">import</span> importlib
importlib.reload(sys)</code></pre></div><p>2）定义方法函数，一个爬虫可能会几百行，所以尽量不要写成一坨</p><div class="hljs"><pre><code class="hljs py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">download</span><span class="hljs-params">(page_no, file_path)</span>:</span>
    <span class="hljs-comment"># 这里写代码逻辑</span></code></pre></div><p>3）定义全局变量</p><div class="hljs"><pre><code class="hljs py"><span class="hljs-comment"># 给请求指定一个请求头来模拟chrome浏览器</span>
<span class="hljs-keyword">global</span> headers <span class="hljs-comment"># 告诉编译器这是全局变量 headers </span>
headers = &#123;<span class="hljs-string">'User-Agent'</span>: <span class="hljs-string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36'</span>&#125;

<span class="hljs-comment"># 函数内使用之前需要</span>
<span class="hljs-comment"># 告诉编译器我在这个方法中使用的a是刚才定义的全局变量 headers ，而不是方法内部的局部变量。</span>
<span class="hljs-keyword">global</span> headers</code></pre></div><p>4）防盗链</p><p>有些网站加入了防盗链，无所不能的 python 解决方案：</p><div class="hljs"><pre><code class="hljs py">headers = &#123;<span class="hljs-string">'Referer'</span>: href&#125;
img = requests.get(url, headers=headers)</code></pre></div><p>5）切换版本</p><p>Linux服务器使用的是阿里云服务器（centos7.4），默认版本 python2，python3 自行安装</p><div class="hljs"><pre><code class="hljs py">[root@AY140216131049Z mzitu]<span class="hljs-comment"># python2 -V</span>
Python <span class="hljs-number">2.7</span><span class="hljs-number">.5</span>
[root@AY140216131049Z mzitu]<span class="hljs-comment"># python3 -V</span>
Python <span class="hljs-number">3.7</span><span class="hljs-number">.1</span>
<span class="hljs-comment"># 默认版本</span>
[root@AY140216131049Z mzitu]<span class="hljs-comment"># python -V</span>
Python <span class="hljs-number">2.7</span><span class="hljs-number">.5</span>
<span class="hljs-comment"># 临时切换版本 &lt;whereis python&gt;</span>
[root@AY140216131049Z mzitu]<span class="hljs-comment"># alias python='/usr/local/bin/python3.7'</span>
[root@AY140216131049Z mzitu]<span class="hljs-comment"># python -V</span>
Python <span class="hljs-number">3.7</span><span class="hljs-number">.1</span></code></pre></div><p>6）异常捕获</p><p>在爬取的过程中可能存在异常页面，这里我们进行捕获，不影响后续操作：</p><div class="hljs"><pre><code class="hljs py"><span class="hljs-keyword">try</span>:
    <span class="hljs-comment"># 业务逻辑</span>
<span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
   print(e)</code></pre></div><h3 id="2-3-执行脚本">2.3 执行脚本</h3><div class="hljs"><pre><code class="hljs py">python3 mzitu.py

<span class="hljs-comment"># 或者后台执行</span>

nohup python3 -u mzitu.py &gt; mzitu.log <span class="hljs-number">2</span>&gt;&amp;<span class="hljs-number">1</span> &amp;</code></pre></div><h2 id="三：-源码">三： 源码</h2><h3 id="3-1-win下代码">3.1 win下代码</h3><div class="hljs"><pre><code class="hljs py"><span class="hljs-comment">#coding=utf-8</span>
<span class="hljs-comment">#!/usr/bin/python</span>
<span class="hljs-comment"># 导入requests库</span>
<span class="hljs-keyword">import</span> requests
<span class="hljs-comment"># 导入文件操作库</span>
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> bs4
<span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup
<span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">import</span> importlib
<span class="hljs-keyword">import</span> random
<span class="hljs-keyword">import</span> time
importlib.reload(sys)


<span class="hljs-comment"># 越多越好</span>
meizi_headers = [
    <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36"</span>,
    <span class="hljs-string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36"</span>,
    <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:30.0) Gecko/20100101 Firefox/30.0"</span>,
    <span class="hljs-string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/537.75.14"</span>,
    <span class="hljs-string">"Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; Win64; x64; Trident/6.0)"</span>,
    <span class="hljs-string">'Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11'</span>,
    <span class="hljs-string">'Opera/9.25 (Windows NT 5.1; U; en)'</span>,
    <span class="hljs-string">'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)'</span>,
    <span class="hljs-string">'Mozilla/5.0 (compatible; Konqueror/3.5; Linux) KHTML/3.5.5 (like Gecko) (Kubuntu)'</span>,
    <span class="hljs-string">'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.8.0.12) Gecko/20070731 Ubuntu/dapper-security Firefox/1.5.0.12'</span>,
    <span class="hljs-string">'Lynx/2.8.5rel.1 libwww-FM/2.14 SSL-MM/1.4.1 GNUTLS/1.2.9'</span>,
    <span class="hljs-string">"Mozilla/5.0 (X11; Linux i686) AppleWebKit/535.7 (KHTML, like Gecko) Ubuntu/11.04 Chromium/16.0.912.77 Chrome/16.0.912.77 Safari/535.7"</span>,
    <span class="hljs-string">"Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:10.0) Gecko/20100101 Firefox/10.0"</span>,
    <span class="hljs-string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36'</span>
]
<span class="hljs-comment"># 给请求指定一个请求头来模拟chrome浏览器</span>
<span class="hljs-keyword">global</span> headers
headers = &#123;<span class="hljs-string">'User-Agent'</span>: random.choice(meizi_headers)&#125;
<span class="hljs-comment"># 爬图网址</span>
mziTu = <span class="hljs-string">'http://www.mzitu.com/'</span>
<span class="hljs-comment"># 定义图片存储位置</span>
<span class="hljs-keyword">global</span> save_path
save_path = <span class="hljs-string">'D:\BeautifulPictures'</span>

<span class="hljs-comment"># 创建文件夹</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">createFile</span><span class="hljs-params">(file_path)</span>:</span>
    <span class="hljs-keyword">if</span> os.path.exists(file_path) <span class="hljs-keyword">is</span> <span class="hljs-literal">False</span>:
        os.makedirs(file_path)
    <span class="hljs-comment"># 切换路径至上面创建的文件夹</span>
    os.chdir(file_path)

<span class="hljs-comment"># 下载文件</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">download</span><span class="hljs-params">(page_no, file_path)</span>:</span>
    <span class="hljs-keyword">global</span> headers
    res_sub = requests.get(page_no, headers=headers)
    <span class="hljs-comment"># 解析html</span>
    soup_sub = BeautifulSoup(res_sub.text, <span class="hljs-string">'html.parser'</span>)
    <span class="hljs-comment"># 获取页面的栏目地址</span>
    all_a = soup_sub.find(<span class="hljs-string">'div'</span>,class_=<span class="hljs-string">'postlist'</span>).find_all(<span class="hljs-string">'a'</span>,target=<span class="hljs-string">'_blank'</span>)
    count = <span class="hljs-number">0</span>
    <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> all_a:
        count = count + <span class="hljs-number">1</span>
        <span class="hljs-keyword">if</span> (count % <span class="hljs-number">2</span>) == <span class="hljs-number">0</span>:
            headers = &#123;<span class="hljs-string">'User-Agent'</span>: random.choice(meizi_headers)&#125;
            print(<span class="hljs-string">"内页第几页："</span> + str(count))
            <span class="hljs-comment"># 提取href</span>
            href = a.attrs[<span class="hljs-string">'href'</span>]
            print(<span class="hljs-string">"套图地址："</span> + href)
            res_sub_1 = requests.get(href, headers=headers)
            soup_sub_1 = BeautifulSoup(res_sub_1.text, <span class="hljs-string">'html.parser'</span>)
            <span class="hljs-comment"># ------ 这里最好使用异常处理 ------</span>
            <span class="hljs-keyword">try</span>:
                <span class="hljs-comment"># 获取套图的最大数量</span>
                pic_max = soup_sub_1.find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'pagenavi'</span>).find_all(<span class="hljs-string">'span'</span>)[<span class="hljs-number">6</span>].text
                print(<span class="hljs-string">"套图数量："</span> + pic_max)
                <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, int(pic_max) + <span class="hljs-number">1</span>):
                    <span class="hljs-comment"># 单位为秒，1-3 随机数</span>
                    time.sleep(random.randint(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>))
                    headers = &#123;<span class="hljs-string">'User-Agent'</span>: random.choice(meizi_headers)&#125;
                    <span class="hljs-comment"># print("子内页第几页：" + str(j))</span>
                    <span class="hljs-comment"># j int类型需要转字符串</span>
                    href_sub = href + <span class="hljs-string">"/"</span> + str(j)
                    print(<span class="hljs-string">"图片地址："</span>+href_sub)
                    res_sub_2 = requests.get(href_sub, headers=headers)
                    soup_sub_2 = BeautifulSoup(res_sub_2.text, <span class="hljs-string">"html.parser"</span>)
                    img = soup_sub_2.find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'main-image'</span>).find(<span class="hljs-string">'img'</span>)
                    <span class="hljs-keyword">if</span> isinstance(img, bs4.element.Tag):
                        <span class="hljs-comment"># 提取src</span>
                        url = img.attrs[<span class="hljs-string">'src'</span>]
                        array = url.split(<span class="hljs-string">'/'</span>)
                        file_name = array[len(array)<span class="hljs-number">-1</span>]
                        <span class="hljs-comment"># 防盗链加入Referer</span>
                        headers = &#123;<span class="hljs-string">'User-Agent'</span>: random.choice(meizi_headers), <span class="hljs-string">'Referer'</span>: url&#125;
                        img = requests.get(url, headers=headers)
                        print(<span class="hljs-string">'开始保存图片'</span>, img)
                        f = open(file_name, <span class="hljs-string">'ab'</span>)
                        f.write(img.content)
                        print(file_name, <span class="hljs-string">'图片保存成功！'</span>)
                        f.close()
            <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
                print(e)


<span class="hljs-comment"># 主方法</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span><span class="hljs-params">()</span>:</span>
    res = requests.get(mziTu, headers=headers)
    <span class="hljs-comment"># 使用自带的html.parser解析</span>
    soup = BeautifulSoup(res.text, <span class="hljs-string">'html.parser'</span>)
    <span class="hljs-comment"># 创建文件夹</span>
    createFile(save_path)
    <span class="hljs-comment"># 获取首页总页数</span>
    img_max = soup.find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'nav-links'</span>).find_all(<span class="hljs-string">'a'</span>)[<span class="hljs-number">3</span>].text
    <span class="hljs-comment"># print("总页数:"+img_max)</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, int(img_max) + <span class="hljs-number">1</span>):
        <span class="hljs-comment"># 获取每页的URL地址</span>
        <span class="hljs-keyword">if</span> i == <span class="hljs-number">1</span>:
            page = mziTu
        <span class="hljs-keyword">else</span>:
            page = mziTu + <span class="hljs-string">'page/'</span> + str(i)
        file = save_path + <span class="hljs-string">'\\'</span> + str(i)
        createFile(file)
        <span class="hljs-comment"># 下载每页的图片</span>
        print(<span class="hljs-string">"套图页码："</span> + page)
        download(page, file)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    main()</code></pre></div><h3 id="3-2-linux下代码">3.2 linux下代码</h3><div class="hljs"><pre><code class="hljs py"><span class="hljs-comment">#coding=utf-8</span>
<span class="hljs-comment">#!/usr/bin/python</span>
<span class="hljs-comment"># 导入requests库</span>
<span class="hljs-keyword">import</span> requests
<span class="hljs-comment"># 导入文件操作库</span>
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> bs4
<span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup
<span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">import</span> importlib
importlib.reload(sys)

<span class="hljs-comment"># 给请求指定一个请求头来模拟chrome浏览器</span>
<span class="hljs-keyword">global</span> headers
headers = &#123;<span class="hljs-string">'User-Agent'</span>: <span class="hljs-string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36'</span>&#125;
<span class="hljs-comment"># 爬图地址</span>
mziTu = <span class="hljs-string">'http://www.mzitu.com/'</span>
<span class="hljs-comment"># 定义存储位置</span>
<span class="hljs-keyword">global</span> save_path
save_path = ​<span class="hljs-string">'/mnt/data/mzitu'</span>

<span class="hljs-comment"># 创建文件夹</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">createFile</span><span class="hljs-params">(file_path)</span>:</span>
    <span class="hljs-keyword">if</span> os.path.exists(file_path) <span class="hljs-keyword">is</span> <span class="hljs-literal">False</span>:
        os.makedirs(file_path)
    <span class="hljs-comment"># 切换路径至上面创建的文件夹</span>
    os.chdir(file_path)

<span class="hljs-comment"># 下载文件</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">download</span><span class="hljs-params">(page_no, file_path)</span>:</span>
    <span class="hljs-keyword">global</span> headers
    res_sub = requests.get(page_no, headers=headers)
    <span class="hljs-comment"># 解析html</span>
    soup_sub = BeautifulSoup(res_sub.text, <span class="hljs-string">'html.parser'</span>)
    <span class="hljs-comment"># 获取页面的栏目地址</span>
    all_a = soup_sub.find(<span class="hljs-string">'div'</span>,class_=<span class="hljs-string">'postlist'</span>).find_all(<span class="hljs-string">'a'</span>,target=<span class="hljs-string">'_blank'</span>)
    count = <span class="hljs-number">0</span>
    <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> all_a:
        count = count + <span class="hljs-number">1</span>
        <span class="hljs-keyword">if</span> (count % <span class="hljs-number">2</span>) == <span class="hljs-number">0</span>:
            print(<span class="hljs-string">"内页第几页："</span> + str(count))
            <span class="hljs-comment"># 提取href</span>
            href = a.attrs[<span class="hljs-string">'href'</span>]
            print(<span class="hljs-string">"套图地址："</span> + href)
            res_sub_1 = requests.get(href, headers=headers)
            soup_sub_1 = BeautifulSoup(res_sub_1.text, <span class="hljs-string">'html.parser'</span>)
            <span class="hljs-comment"># ------ 这里最好使用异常处理 ------</span>
            <span class="hljs-keyword">try</span>:
                <span class="hljs-comment"># 获取套图的最大数量</span>
                pic_max = soup_sub_1.find(<span class="hljs-string">'div'</span>,class_=<span class="hljs-string">'pagenavi'</span>).find_all(<span class="hljs-string">'span'</span>)[<span class="hljs-number">6</span>].text
                print(<span class="hljs-string">"套图数量："</span> + pic_max)
                <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, int(pic_max) + <span class="hljs-number">1</span>):
                    <span class="hljs-comment"># print("子内页第几页：" + str(j))</span>
                    <span class="hljs-comment"># j int类型需要转字符串</span>
                    href_sub = href + <span class="hljs-string">"/"</span> + str(j)
                    print(href_sub)
                    res_sub_2 = requests.get(href_sub, headers=headers)
                    soup_sub_2 = BeautifulSoup(res_sub_2.text, <span class="hljs-string">"html.parser"</span>)
                    img = soup_sub_2.find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'main-image'</span>).find(<span class="hljs-string">'img'</span>)
                    <span class="hljs-keyword">if</span> isinstance(img, bs4.element.Tag):
                        <span class="hljs-comment"># 提取src</span>
                        url = img.attrs[<span class="hljs-string">'src'</span>]
                        array = url.split(<span class="hljs-string">'/'</span>)
                        file_name = array[len(array)<span class="hljs-number">-1</span>]
                        <span class="hljs-comment"># print(file_name)</span>
                        <span class="hljs-comment"># 防盗链加入Referer</span>
                        headers = &#123;<span class="hljs-string">'Referer'</span>: href&#125;
                        img = requests.get(url, headers=headers)
                        <span class="hljs-comment"># print('开始保存图片')</span>
                        f = open(file_name, <span class="hljs-string">'ab'</span>)
                        f.write(img.content)
                        <span class="hljs-comment"># print(file_name, '图片保存成功！')</span>
                        f.close()
            <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
                print(e)


<span class="hljs-comment"># 主方法</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span><span class="hljs-params">()</span>:</span>
    res = requests.get(mziTu, headers=headers)
    <span class="hljs-comment"># 使用自带的html.parser解析</span>
    soup = BeautifulSoup(res.text, <span class="hljs-string">'html.parser'</span>)
    <span class="hljs-comment"># 创建文件夹</span>
    createFile(save_path)
    <span class="hljs-comment"># 获取首页总页数</span>
    img_max = soup.find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'nav-links'</span>).find_all(<span class="hljs-string">'a'</span>)[<span class="hljs-number">3</span>].text
    <span class="hljs-comment"># print("总页数:"+img_max)</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, int(img_max) + <span class="hljs-number">1</span>):
        <span class="hljs-comment"># 获取每页的URL地址</span>
        <span class="hljs-keyword">if</span> i == <span class="hljs-number">1</span>:
            page = mziTu
        <span class="hljs-keyword">else</span>:
            page = mziTu + <span class="hljs-string">'page/'</span> + str(i)
        file = save_path + <span class="hljs-string">'/'</span> + str(i)
        createFile(file)
        <span class="hljs-comment"># 下载每页的图片</span>
        print(<span class="hljs-string">"套图页码："</span> + page)
        download(page, file)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    main()</code></pre></div><h2 id="四：-参考文献">四： 参考文献</h2><p><a href="https://gitee.com/52itstyle/Python" target="_blank" rel="noopener">小柒2012 / 从零学Python / Day01</a></p></article><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/python/">python</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/python/">python</a> <a class="hover-with-bg" href="/tags/%E7%88%AC%E5%9B%BE/">爬图</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p><div class="post-prevnext row"><div class="post-prev col-6"><a href="/2020/02/16/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Python/you-get%E4%B8%8B%E8%BD%BD%E8%A7%86%E9%A2%91/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">you-get下载视频</span> <span class="visible-mobile">上一篇</span></a></div><div class="post-next col-6"><a href="/2020/02/15/hexo/hexo%E4%B8%80%E9%94%AE%E4%B8%8A%E4%BC%A0%E9%83%A8%E7%BD%B2%E8%84%9A%E6%9C%AC%E7%9A%84%E6%9E%84%E5%BB%BA/"><span class="hidden-mobile">hexo一键上传部署脚本的构建</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></div></div></div><div class="comments" id="comments"><div id="vcomments"></div><script defer src="https://cdn.staticfile.org/valine/1.4.14/Valine.min.js"></script><script type="text/javascript">var oldLoadVa=window.onload;window.onload=function(){oldLoadVa&&oldLoadVa(),new Valine({el:"#vcomments",app_id:"YzLqNtMw1YEwwACli1FUsIUM-gzGzoHsz",app_key:"HLUt5izfTvTcbEbOrA59W92a",placeholder:"畅所欲言...",path:window.location.pathname,avatar:"robohash",meta:["nick","mail","link"],pageSize:"10",lang:"zh-CN",highlight:!0,recordIP:!1,serverURLs:""})}</script><noscript>Please enable JavaScript to view the <a href="https://valine.js.org" target="_blank" rel="nofollow noopener noopener">comments powered by Valine.</a></noscript></div></div></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div id="tocbot"></div></div></div></div></div><div class="col-lg-7 mx-auto nopadding-md"><div class="container custom post-content mx-auto"><img src="https://closer_laps.coding.net/p/picture/d/picture/git/raw/master/pay/pay.png" srcset="/img/loading.gif" class="rounded mx-auto d-block mt-3" style="width:355.4px;height:200px"></div></div></main><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div><div id="aplayer"></div><script defer src="https://cdn.staticfile.org/aplayer/1.10.1/APlayer.min.js"></script><link rel="stylesheet" href="https://cdn.staticfile.org/aplayer/1.10.1/APlayer.min.css"><script type="text/javascript">var oldLoadAp=window.onload;window.onload=function(){oldLoadAp&&oldLoadAp(),new APlayer({container:document.getElementById("aplayer"),fixed:!0,autoplay:!1,loop:"all",order:"random",theme:"#b7daff",preload:"none",audio:[{name:"灰色空间",artist:"罗志祥",url:"https://closer_laps.coding.net/p/picture/d/picture/git/raw/master/music/%E7%81%B0%E8%89%B2%E7%A9%BA%E9%97%B4%20-%20%E7%BD%97%E5%BF%97%E7%A5%A5.mp3",cover:"https://closer_laps.coding.net/p/picture/d/picture/git/raw/master/music/luozhixiang.png"}]})}</script><footer class="mt-5"><div class="text-center py-3"><div><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script><script src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js"></script><script src="/js/main.js"></script><script src="/js/lazyload.js"></script><script src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js"></script><script>$(document).ready(function(){var t=$("#board-ctn").offset().top;tocbot.init({tocSelector:"#tocbot",contentSelector:".post-content",headingSelector:"h1,h2,h3,h4,h5,h6",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",collapseDepth:0,scrollSmooth:!0,headingsOffset:-t}),0<$(".toc-list-item").length&&$("#toc").css("visibility","visible")})</script><script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js"></script><script src="/js/clipboard-use.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script defer>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?608f2baddd361128381ad2bf9377bf89";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js"></script><script>var typed=new Typed("#subtitle",{strings:["  ","python爬图攻略&nbsp;"],cursorChar:"_",typeSpeed:70,loop:!1});typed.stop(),$(document).ready(function(){$(".typed-cursor").addClass("h2"),typed.start()})</script><script src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js"></script><script>anchors.options = {
      placement: "right",
      visible: "always",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))</script><script src="/js/local-search.js"></script><script>var path="/local-search.xml",inputArea=document.querySelector("#local-search-input");inputArea.onclick=function(){searchFunc(path,"local-search-input","local-search-result"),this.onclick=null}</script><script src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js"></script><link rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css"><script>$("#post img:not(.no-zoom img, img[no-zoom]), img[zoom]").each(function(){var t=document.createElement("a");$(t).attr("data-fancybox","images"),$(t).attr("href",$(this).attr("src")),$(this).wrap(t)})</script><script>MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };</script><script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js"></script><script type="text/javascript">var a_idx=0;jQuery(document).ready(function(d){d("body").click(function(a){var o=new Array("富强","民主","文明","和谐","自由","平等","公正","法治","爱国","敬业","诚信","友善"),t=d("<span/>").text(o[a_idx]);a_idx=(a_idx+1)%o.length;var n=a.pageX,e=a.pageY;t.css({"z-index":999,top:e-20,left:n,position:"absolute","font-weight":"bold",color:"rgb("+~~(255*Math.random())+","+~~(255*Math.random())+","+~~(255*Math.random())+")"}),d("body").append(t),t.animate({top:e-180,opacity:0},1500,function(){t.remove()})})})</script><script>!function(e,t,o,a,c,i,n){e.DaoVoiceObject=c,e[c]=e[c]||function(){(e[c].q=e[c].q||[]).push(arguments)},e[c].l=1*new Date,i=t.createElement(o),n=t.getElementsByTagName(o)[0],i.async=1,i.src=a,i.charset="utf-8",n.parentNode.insertBefore(i,n)}(window,document,"script",("https:"===document.location.protocol?"https:":"http:")+"//widget.daovoice.io/widget/aa03e448.js","daovoice"),daovoice("init",{app_id:"aa03e448"}),daovoice("update")</script></body></html>